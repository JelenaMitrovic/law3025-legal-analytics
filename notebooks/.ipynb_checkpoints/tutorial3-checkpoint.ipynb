{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legal Analytics (LAW3025) - Tutorial 3: 'Data Cleaning in Python'\n",
    "\n",
    "*Version*: 2021/2022\n",
    "\n",
    "This tutorial  provides a brief introduction to data quality assessment and cleaning in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data science model\n",
    "\n",
    "After doing the required reading for this week, you are now familiar with the CRISP-DM model:\n",
    "<p align=\"center\"><img src='./img/CRISP-dm.png' width=\"300\" height=\"300\"></p>\n",
    "\n",
    "This model shows from a high-level how (messy) Data Science can be. In this tutorial, we'll take a closer look at data understanding and data preparation. You will assess the data quality of a dataset and you will clean the dataset to increase the data quality. Next week, we'll increase our knowledge of data understanding by doing a exploratory data analysis.\n",
    "\n",
    "### Data quality\n",
    "There is an old adage in computer science - 'Garbage in, garbage out'. The key ingredient in any data science process is data, and inaccurate data may negatively affect the results of data analysis and ensuing decisions. It is therefore not surprising that data scientists spend nearly 70% of their time cleaning the data prior to their analysis. \n",
    "\n",
    "While different experts have proposed different sets of data quality dimensions, almost all include the following six or a version thereof: \n",
    "- <b>Validity</b>:\n",
    "Does the data conform to the format, range and type of its definition?\n",
    "\n",
    "- <b>Consistency</b>:\n",
    "Is the data consistent (within the same dataset/across multiple datasets)?\n",
    "\n",
    "- <b>Uniqueness</b>:\n",
    "Are the elements uniquely identified throughout the dataset? (i.e. no duplicate data is recorded)\n",
    "\n",
    "- <b>Completeness</b>:\n",
    "Are there missing values (empty cells, tables, files, etc.) in the data? \n",
    "\n",
    "- <b>Accuracy</b>:\n",
    "Does the data represent the real world? \n",
    "\n",
    "- <b>Timeliness</b>:\n",
    "Does the data represent the reality at the required moment in time?\n",
    "\n",
    "As data accuracy and timeliness cannot be assessed in an automated manner in the absence of a gold standard, we will not be dealing with these two dimensions in this tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data\n",
    "For this workshop, we will be using a <b>modified version</b> of the 'Climate Laws and Policies' dataset compiled by the Grantham Research Institute at LSE and the Sabin Center at Columbia Laws School. The original dataset is available at [climate-laws.org](https://climate-laws.org/cclow). \n",
    "\n",
    "The csv file that we will be using (`climate_change_laws.csv`) <b>is available at: https://github.com/maastrichtlawtech/law3025-legal-analytics/blob/main/dataset/climate_change_laws.csv. You can download it on your local computer.</b>. \n",
    "\n",
    "Here is a description of the columns (in order) present in this csv file:\n",
    "\n",
    "\n",
    "| Column | Description | \n",
    "| :--- | :--- |\n",
    "| Title | the title of the law |\n",
    "| Description | a description of the law's provisions |\n",
    "| Type | the type of the measure ('legislative' or 'executive') |\n",
    "| Geography | the enacting state |\n",
    "| Geography Code | the ISO 3166 three-letter country code of the enacting state |\n",
    "| Frameworks | the aim of the measures outlined in the law ('mitigation', 'adaptation' or 'mitigation and adaptation') |\n",
    "| Keywords | the main issues addressed by the law |\n",
    "| Events | the date of adoption and, if applicable, the date of amendment of the law |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data into a dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic data understanding\n",
    "\n",
    "In these first steps, you will get a basic understanding of the dataset. You will:\n",
    "- check the shape of the dataframe; \n",
    "- print a summary of the dataframe; and\n",
    "- examine the first and last rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the shape of the dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print a summary of the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this summary, you see that the column 'Frameworks' includes many `null` entries. This column certainly deserves a closer look later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine the first couple of rows of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine the last couple of rows of the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the column data types. Do they correspond to what they should be? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find out what values a variable of interest takes applying the pandas ```unique()``` function to a column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine what unique values the variable 'Frameworks' can take\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some values are `No`; this simply means that there is no data available on the framework established by a particular law.\n",
    "Let's find out how many entries take the value `No`. To find out the frequency distribution of a categorical column, we can use the pandas ```value_counts()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine how many entries in the 'Frameworks' column take the value 'No'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the rows in which the variable 'Frameworks' takes the value 'No'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the value 'No' with NaN in the selected rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the frequency distribution of the 'Frameworks' column again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at what unique values the variable 'Frameworks' can take again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in a tabular dataset, each row represents an observation and each column represents a variable. However, the `Events` column clearly represents two variables: the date when a law was passed and, if applicable, the law when it was amended. The two variables are delimited by `;`. We can use the pandas `str.split()` method to split the `Events` column into two columns - `Law passed` and `Law amended`, around the delimiter `;`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the 'Events' column into two columns - 'Law passed' and 'Law amended'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we split the `Events` column into `Law passed` and `Law amended`, we can delete it using the pandas  ```drop()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete the 'Events' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take another look at the first couple of rows of the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it is now clear at what date a law was passed, and, if applicable, amended, it is no longer needed to specify that in the relevant cells. In fact, the accompanying text will impede any analyses we may want to perform using the two columns. It's therefore time we got rid of the text and kept the date strings only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the redundant data in the 'Law passed column'\n",
    "# Hint: you can use the str.split() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the redundant data in the 'Law amended column'\n",
    "# Hint: you can use the str.split() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take another look at the first couple of rows of the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to convert our date strings to ```datetime```, a data type specifically designed for dates and times. We can use the pandas ```to_datetime``` function to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the date strings in the 'Law passed' column to datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the date strings in the 'Law amended' column to datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at the column data types again \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Look again at what unique values the variable 'Frameworks' takes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notation of the values the variable `Frameworks` can take is not uniform - the values `mitigation` and `mitigation and adaptation` are not always written in the same case. This may not be a problem for us (humans), as the meaning of the values does not change. This is, however, a problem for computers - sadly, they do not understand meaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the value 'Mitigation and adaptation' with 'Mitigation and Adaptation' in the 'Frameworks' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the value 'mitigation' with 'Mitigation' in the 'Frameworks' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check what unique values the variable 'Frameworks' takes now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Uniqueness\n",
    "To identify duplicate rows in our dataset, we can use the pandas ```duplicated()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are any duplicate rows in our dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate rows can be deleted using the pandas ```drop_duplicates()``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the duplicate rows \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset the dataframe index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check what the length of the dataframe is now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine how many missing values (if any) there are per column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the index of missing values in a column (e.g. 'Description')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print rows that do not have a null value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check which rows have a null value\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
